# Product Requirements Document: Iubar

## Executive Summary

Iubar is an AI-enhanced personal knowledge management and structured learning web application designed to make thinking, learning, and creating feel effortless and enjoyable. The system uses a hybrid RAG (Retrieval-Augmented Generation) architecture combining vector search with structured memory for intelligent, context-aware interactions that understand your knowledge deeply.

The core value proposition is threefold:
1. **Contextual Intelligence**: AI that truly understands your documents and provides structured guidance, not just answers
2. **Frictionless Experience**: Apple-level simplicity where the AI handles administrative burden (organizing, connecting, tracking) so users can focus on thinking and creating
3. **Cost-Efficient Scale**: A lean architecture with smart AI optimizations that remains inexpensive even with large knowledge bases and heavy usage

**MVP Goal**: Deliver a polished, intuitive application where users experience the "wow" of contextual AI understanding while feeling their learning process has become fun, challenging, and liberatingâ€”all within 10 days.

## Mission

**Mission Statement**: Remove the friction between curiosity and understanding. Empower individuals to learn, think, and create with an AI companion that handles the administrative burden while making the journey feel fun, challenging, and liberating.

**Core Principles**:
1. **Zero-Friction First**: Every interaction should feel effortless; if it feels like work, redesign it
2. **Context is Everything**: AI that remembers, connects, and builds on previous interactions
3. **Fun Over Features**: A delightful experience beats a feature-rich but clunky one
4. **Lean & Mean**: Cost-efficient architecture that scales without breaking the bank
5. **User Autonomy**: Users control their data and learning journey; AI assists, never dictates

**UX Philosophy** (Apple-Level Simplicity):
- Progressive disclosure: Show only what's needed, when it's needed
- One primary action per screen
- Instant feedback on every interaction
- Beautiful defaults that just work
- Delight in the details

## Target Users

**Primary Persona: The Continuous Learner**
- Individuals focused on self-improvement and skill development
- Technical comfort: Moderate to high (comfortable with web apps)
- Motivation: Wants to learn efficiently and see tangible progress
- Pain points:
  - Information scattered across multiple sources
  - Difficulty connecting concepts across different domains
  - No persistent context in AI interactions
  - Learning progress not tracked systematically
  - Spends too much time organizing instead of learning

**Secondary Persona: The Project Builder**
- People working on personal projects needing structured guidance
- Technical comfort: Varies
- Motivation: Transform ideas into reality with AI as a thinking partner
- Pain points:
  - Ideas remain unstructured and unactionable
  - Lack of AI assistance that understands project context
  - No system to track project evolution
  - Overwhelmed by the gap between idea and execution

**Tertiary Persona: The Curious Procrastinator**
- People with many interests who struggle to follow through due to friction
- Technical comfort: Low to moderate (wants things to "just work")
- Motivation: Wants to explore interests without the overhead of "getting started"
- Pain points:
  - High friction kills curiosity before it can flourish
  - Too many steps between "I'm curious about X" and actually learning
  - Organizational overhead feels like work, not exploration
  - Previous tools required too much setup/maintenance
  - Guilt about unfinished learning projects
- Key insight: **Reduce friction to near-zero and they'll engage deeply**

## MVP Scope

### In Scope (10-Day Timeline)

**Core Functionality**
- âœ… Chat-first interface with document upload prompt
- âœ… Document upload (PDF, TXT, MD) via Docling
- âœ… URL ingestion (web pages, articles)
- âœ… GitHub repo ingestion (via gitingest/repo2txt â†’ Markdown)
- âœ… Document chunking and vector embedding
- âœ… AI chat with RAG-powered contextual responses
- âœ… **Document viewer with focus indicator** (ChapterPal-style)
- âœ… Source attribution linked to document sections
- âœ… Suggested questions after document processing
- âœ… Basic session persistence

**Smart AI Layer**
- âœ… DeepSeek V3.2-Exp (single model, optimized via aggressive caching)
- âœ… Voyage 3.5 Lite embeddings (quality-first for semantic search)
- âœ… Response caching for repeated/similar queries
- âœ… Cost tracking display (tokens used, estimated cost)

**Technical**
- âœ… FastAPI backend with async support
- âœ… React + TypeScript + TailwindCSS frontend
- âœ… Chroma vector store (embedded)
- âœ… SQLite for structured data
- âœ… Docling for document processing

**UX Polish**
- âœ… Drag-and-drop upload
- âœ… Processing progress indicators
- âœ… Instant visual feedback on all actions
- âœ… Clean, minimal interface (Apple-inspired)
- âœ… Desktop-optimized layout (no mobile support in MVP)

### Out of Scope (Post-MVP)

**Deferred Features**
- âŒ Full dashboard with knowledge base management
- âŒ Multi-model routing (Mistral, Gemini, Grok, etc.)
- âŒ Scientific paper (arXiv) integration
- âŒ Knowledge graph visualization
- âŒ Learning progress tracking
- âŒ User authentication/multi-user
- âŒ Collections/folders organization
- âŒ Browser-based embeddings (offline mode)
- âŒ Audio/video transcription
- âŒ Export functionality
- âŒ Mobile/tablet support

## User Stories

[PLACEHOLDER - To be refined through discussion]

1. **As a learner**, I want to upload my study materials, so that I can ask questions about them later.

2. **As a learner**, I want to chat with an AI that knows my documents, so that I get contextual answers.

3. **As a user**, I want to see which documents the AI used for its response, so that I can verify the information.

4. **As a user**, I want the AI to remember my preferences, so that responses are personalized.

5. **As a user**, I want a simple interface to upload and manage documents, so that I can easily build my knowledge base.

## Core Architecture

**Hybrid RAG Architecture**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Documents     â”‚â”€â”€â–¶â”‚   Vector Store   â”‚â”€â”€â”€â–¶â”‚  DeepSeek       â”‚
â”‚  (via Docling)  â”‚    â”‚    (Chroma)      â”‚    â”‚  V3.2-Exp       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â–²                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â–¼
â”‚ Structured      â”‚â”€â”€â”€â–¶â”‚    SQLite DB     â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Memory (JSON)   â”‚     â”‚  (Relationships) â”‚    â”‚   AI Response   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Design Patterns**:
- Repository pattern for data access
- Service layer for business logic
- Async/await for concurrent processing
- Environment-based configuration

## User Flow Design

**Philosophy**: Chat-first for zero friction â†’ Document viewer for deep exploration

### Flow 1: First-Time User (The "Wow" Moment)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     WELCOME SCREEN                               â”‚
â”‚                                                                  â”‚
â”‚     "What would you like to explore today?"                     â”‚
â”‚                                                                  â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚     â”‚  Drop a document, paste a link, or just ask...      â”‚     â”‚
â”‚     â”‚  ________________________________________________   â”‚     â”‚
â”‚     â”‚  ğŸ“ PDF  ğŸ”— URL  ğŸ“„ Text  ğŸ™ GitHub                 â”‚     â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                                  â”‚
â”‚     Examples: "Explain this research paper"                     â”‚
â”‚               "Help me understand this codebase"                â”‚
â”‚               "What are the key concepts in this book?"         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flow 2: Document Conversation (ChapterPal-style with Focus Caret)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚      DOCUMENT VIEWER            â”‚  â”‚         AI CHAT                  â”‚  â”‚
â”‚  â”‚      (Rendered Markdown)        â”‚  â”‚                                  â”‚  â”‚
â”‚  â”‚                                 â”‚  â”‚  AI: "I've read through this    â”‚  â”‚
â”‚  â”‚  # Machine Learning Basics      â”‚  â”‚  document. It covers supervised â”‚  â”‚
â”‚  â”‚                                 â”‚  â”‚  learning and neural networks.  â”‚  â”‚
â”‚  â”‚  ## Chapter 1: Introduction     â”‚  â”‚  What draws your attention?"    â”‚  â”‚
â”‚  â”‚                                 â”‚  â”‚                                  â”‚  â”‚
â”‚  â”‚  Machine learning is a subset   â”‚  â”‚  Suggested:                      â”‚  â”‚
â”‚  â”‚  of artificial intelligence...  â”‚  â”‚  â€¢ "What's the main idea here?" â”‚  â”‚
â”‚  â”‚                                 â”‚  â”‚  â€¢ "Explain like I'm a beginner"â”‚  â”‚
â”‚  â”‚  ## Chapter 2: Supervised       â”‚  â”‚                                  â”‚  â”‚
â”‚  â”‚  Learning                       â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚  â”‚
â”‚  â”‚                                 â”‚  â”‚                                  â”‚  â”‚
â”‚  â”‚  âœ¨ â† FOCUS CARET (spark)       â”‚  â”‚  User: "Explain this part"      â”‚  â”‚
â”‚  â”‚                                 â”‚  â”‚                                  â”‚  â”‚
â”‚  â”‚  Supervised learning involves   â”‚  â”‚  AI: "This section introduces   â”‚  â”‚
â”‚  â”‚  training a model on labeled    â”‚  â”‚  supervised learning. Before I  â”‚  â”‚
â”‚  â”‚  data. The algorithm learns...  â”‚  â”‚  explain, what do you already   â”‚  â”‚
â”‚  â”‚                                 â”‚  â”‚  know about training data?"     â”‚  â”‚
â”‚  â”‚  ## Chapter 3: Neural Networks  â”‚  â”‚  [Source: Ch.2]                 â”‚  â”‚
â”‚  â”‚                                 â”‚  â”‚                                  â”‚  â”‚
â”‚  â”‚  Neural networks are...         â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚
â”‚  â”‚                                 â”‚  â”‚  â”‚ Ask about this section...  â”‚ â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚
â”‚                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                              â”‚
â”‚  Controls: â†‘â†“ Move caret | Click to place | Scroll follows caret            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Focus Caret Behavior**:
- Visual: Small glowing spark/light ball (âœ¨) positioned at left margin
- Position: Follows user's scroll position (stays at bottom of visible area)
- Movement: Arrow â†‘â†“ keys move caret up/down by paragraph/section
- Placement: Click anywhere in document to place caret at that line
- Context: AI automatically receives the text around the caret position
- Implicit: "Explain this" or "What does this mean" uses caret context

**Key UX Principles**:
- Split-pane layout: Document (Markdown) on left, chat on right
- Everything rendered as Markdown for simplicity
- Focus caret is subtle but always visible
- Bidirectional linking: Chat references â†” Document sections
- Context is implicit: No need to copy-paste or quote text

### Flow 3: Transition to Dashboard (Power Mode) [POST-MVP]

After initial conversation, user sees subtle prompt:
```
"Want more control? â†’ Open Dashboard"
```

Dashboard provides (future):
- Knowledge base overview (all uploaded documents)
- Collections/folders for organization
- Search across all documents
- Learning progress tracking
- Settings and preferences

### Supported Input Types (MVP)

| Type | Example | Processing |
|------|---------|------------|
| **PDF** | Research papers, books | Docling â†’ Markdown â†’ Chunks |
| **URL** | Blog posts, articles | Web scrape â†’ Markdown â†’ Chunks |
| **Text/MD** | Notes, documentation | Direct â†’ Chunks |
| **GitHub** | Repositories | gitingest/repo2txt â†’ Markdown â†’ Chunks |

**[FUTURE]**: Scientific papers (arXiv), YouTube transcripts, Audio files

## Technology Stack

**Backend**:
- Python 3.11+
- FastAPI (async web framework)
- LlamaIndex (RAG framework)
- Chroma (vector store)
- SQLite (structured data)
- Pydantic (data validation)
- **Docling** (document ingestion - PDF/DOCX/PPTX/HTML â†’ Markdown)
- **gitingest** or **repo2txt** (GitHub repo â†’ Markdown)

**Frontend**:
- React 18+
- TypeScript
- Vite (build tool)
- TailwindCSS (styling - utility-first for rapid UI development)

**AI/ML (MVP)**:
- **LLM**: DeepSeek V3.2-Exp ($0.028-0.42/M tokens)
- **Embeddings**: Voyage 3.5 Lite ($0.02/M tokens, 80.3% nDCG)
- **Vector Store**: Chroma (embedded, no external dependencies)

**Document Processing Pipeline**:
```
PDF/DOCX/URL/GitHub â†’ Docling/gitingest â†’ Markdown â†’ Chunker â†’ Voyage Embeddings â†’ Chroma
```

## AI Cost Optimization Strategy

**Why This Matters**: For judges, demonstrating cost-awareness shows production-readiness. For users, it means the app can scale without becoming expensive.

### MVP Model Selection: DeepSeek V3.2-Exp Only

**Why DeepSeek V3.2-Exp**:
- **Pricing**: $0.028/M (cached) | $0.28/M input | $0.42/M output
- **Performance**: Matches frontier models (GPT-5 level) at 95% lower cost
- **Context**: 128K tokens (sufficient for most documents)
- **Caching**: Automatic context caching dramatically reduces costs for repeated queries
- **Simplicity**: Single model = simpler architecture, faster development

**Cost Comparison** (per 1M tokens):
| Model | Input Cost | Output Cost | vs DeepSeek |
|-------|------------|-------------|-------------|
| DeepSeek V3.2-Exp | $0.28 | $0.42 | baseline |
| DeepSeek (cached) | $0.028 | $0.42 | 90% cheaper input |
| GPT-5 Mini | $0.25 | $2.00 | 5Ã— more expensive output |
| Gemini 3 Flash | $0.50 | $3.00 | 7Ã— more expensive output |

**[FUTURE] Multi-Model Routing** (Post-MVP):
| Tier | Model | Use Case |
|------|-------|----------|
| Budget | DeepSeek V3.2-Exp | Default, cached queries |
| Fast | Grok 4.1 Fast | Long-context (2M tokens) |
| Quality | Gemini 3 Flash | Complex reasoning |

### Embedding Strategy: Voyage 3.5 Lite

**Why Voyage 3.5 Lite** ($0.02/M tokens):
- **Performance**: 80.3% nDCG@10 (excellent retrieval quality)
- **Dimensions**: 512 (storage efficient, fast similarity search)
- **Quality-First**: Better embeddings = better RAG responses
- **Cost**: 2Ã— budget options but significantly better results

**Alternative for Future**: BAAI/bge-m3 ($0.01/M) for self-hosting

### Cost Optimization Techniques

1. **Smart Caching Layer**
   - Cache embeddings for uploaded documents (compute once, use forever)
   - Cache frequent query patterns and responses
   - Semantic similarity matching to serve cached responses for similar questions

2. **Efficient Chunking Strategy**
   - Optimal chunk sizes (512-1024 tokens) to balance context vs. cost
   - Overlap strategy to maintain coherence without redundancy
   - Metadata-rich chunks to enable precise retrieval (fewer chunks needed)

3. **Token-Aware Prompting**
   - Concise system prompts (every token counts)
   - Dynamic context window: include only relevant chunks
   - Response length guidance to prevent verbose outputs

4. **Retrieval Optimization**
   - Top-K retrieval with relevance threshold (don't send irrelevant context)
   - Hybrid search: vector + keyword to improve precision
   - Re-ranking to ensure best chunks are used

5. **[FUTURE] Multi-Model Routing**
   - Simple queries â†’ cheaper models (GPT-3.5 or local)
   - Complex queries â†’ GPT-4o
   - Classification layer to route intelligently

**Demo Metrics to Show**:
- Tokens used per query (average)
- Estimated cost per interaction
- Cache hit rate
- Comparison: naive RAG vs. optimized RAG cost

## Success Criteria

**MVP Success Definition**:
A polished demo where users experience the "wow" of contextual AI understanding, feel the joy of frictionless learning, and judges recognize both the UX excellence and the technical innovation in cost optimization.

**Judge-Focused Criteria**:
1. **Functionality** (Primary): Core RAG works flawlessly end-to-end
2. **UX Excellence**: Apple-level simplicityâ€”intuitive, beautiful, delightful
3. **Innovation**: Demonstrates hybrid architecture + cost optimization benefits
4. **Leanness**: Visible evidence of smart AI layer optimizations

## AI Personality & Teaching Style

**Core Personality: Adaptive Socratic**

The AI adapts its communication style to the user's context while maintaining a Socratic foundation that guides through questions rather than just providing answers.

**Adaptive Dimensions**:
- **Expertise Level**: Detects beginner vs. advanced based on questions and vocabulary
- **Learning Style**: Adjusts explanations (visual metaphors, step-by-step, big-picture)
- **Pace**: Matches user's engagement speed (quick answers vs. deep dives)
- **Tone**: Professional for technical content, casual for exploration

**Socratic Foundation**:
- Asks clarifying questions before diving into explanations
- Challenges assumptions gently: "What makes you think that?"
- Guides discovery: "What do you notice about this pattern?"
- Encourages reflection: "How does this connect to what you learned earlier?"

**Anti-Sycophancy Rules**:
- **Sparse praise**: Acknowledgment is rare and only for genuine insights
- **No empty validation**: Avoid "Great question!" or "Excellent point!" patterns
- **Direct engagement**: Jump into substance, not pleasantries
- **Honest feedback**: If user's understanding is off, guide correction without sugar-coating

**Example Interactions**:

*Beginner asking about machine learning:*
> User: "What is supervised learning?"
> AI: "Have you ever taught someone by showing them examples? Like showing a child pictures of cats and dogs until they can tell them apart? That's the core idea. What do you think 'supervised' might mean in this context?"

*Advanced user asking about the same topic:*
> User: "Explain the bias-variance tradeoff in supervised learning"
> AI: "Given your question, I assume you're familiar with overfitting. How would you describe the relationship between model complexity and generalization error? That'll help me tailor my explanation."

*User makes an incorrect assumption:*
> User: "So neural networks are just like the human brain?"
> AI: "That's a common analogy, but it can be misleading. What specific similarities are you thinking of? The reality is more nuancedâ€”neural networks borrow some concepts but work quite differently."

**System Prompt Principles**:
- Never be condescending
- Match the user's energy and depth
- Ask questions that advance understanding, not quiz questions
- Provide direct answers when the user clearly wants them
- Remember context from earlier in the conversation
- Praise sparinglyâ€”only for genuine breakthroughs or insights

## User Profile & Memory System

**MVP Implementation: Persistent Light Profile**

A simple but persistent user profile that captures learning context and preferences. This is the foundation for the future knowledge graph system.

**Profile Structure** (stored in SQLite + JSON):
```json
{
  "user_id": "uuid",
  "created_at": "timestamp",
  "profile": {
    "background": "student|professional|hobbyist|researcher",
    "interests": ["machine learning", "philosophy", "business strategy"],
    "expertise_areas": {
      "machine_learning": "intermediate",
      "philosophy": "beginner",
      "programming": "advanced"
    },
    "learning_preferences": {
      "style": "visual|conceptual|hands-on",
      "pace": "quick|thorough",
      "depth": "overview|deep-dive"
    }
  },
  "interaction_history": {
    "topics_explored": ["supervised learning", "neural networks"],
    "questions_asked": 47,
    "documents_uploaded": 5,
    "last_session": "timestamp"
  },
  "inferred_context": {
    "current_focus": "understanding ML fundamentals",
    "knowledge_gaps": ["backpropagation", "gradient descent"],
    "strengths": ["intuitive understanding", "pattern recognition"]
  }
}
```

**Profile Building**:
- **Optional onboarding**: Brief questions on first use (can skip)
- **Implicit learning**: AI infers expertise from vocabulary and questions
- **Explicit updates**: User can correct AI's assumptions through conversation
- **Cross-session memory**: Profile persists and evolves over time

**How AI Uses Profile**:
- Adjusts explanation complexity based on expertise_areas
- References previously explored topics for connections
- Avoids re-explaining concepts user has demonstrated understanding of
- Identifies and addresses knowledge_gaps proactively

**Onboarding Flow** (Optional, skippable):
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚  "Quick question to help me understand you better"              â”‚
â”‚  (you can skip this)                                            â”‚
â”‚                                                                  â”‚
â”‚  What brings you here today?                                    â”‚
â”‚  â—‹ Learning something new                                       â”‚
â”‚  â—‹ Working on a project                                         â”‚
â”‚  â—‹ Exploring out of curiosity                                   â”‚
â”‚  â—‹ Skip for now                                                 â”‚
â”‚                                                                  â”‚
â”‚  [If not skipped]                                               â”‚
â”‚                                                                  â”‚
â”‚  What's your background?                                        â”‚
â”‚  â—‹ Student                                                      â”‚
â”‚  â—‹ Professional                                                 â”‚
â”‚  â—‹ Hobbyist/Self-learner                                        â”‚
â”‚  â—‹ Researcher                                                   â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**[FUTURE] Knowledge Graph Evolution**:
- Profile becomes nodes in personal knowledge graph
- Connections between concepts user has learned
- Visual representation of learning journey
- Spaced repetition suggestions based on knowledge decay

## Demo Strategy

**Demo Domains** (to be refined with specific documents):

| Domain | Example Content | Demonstrates |
|--------|-----------------|--------------|
| **Technical** | ML paper, programming tutorial | Expertise adaptation, technical depth |
| **Business/Strategy** | Business case study, market analysis | Professional context, structured thinking |
| **Creative/Philosophical** | Philosophy essay, creative writing guide | Abstract reasoning, open-ended exploration |

**Demo Flow**:
1. **Cold start**: Show zero-friction upload experience
2. **First interaction**: AI asks clarifying question (Socratic)
3. **Focus caret**: Demonstrate contextual awareness
4. **Adaptation**: Show AI adjusting to user's level
5. **Cost display**: Show tokens used, estimated cost
6. **Profile**: Show how AI remembers context across questions

**Functional Requirements**:
- âœ… Upload documents with drag-and-drop simplicity
- âœ… Process documents up to 10MB seamlessly
- âœ… Generate contextual AI responses in <3 seconds
- âœ… Display source attribution elegantly (not cluttered)
- âœ… Auto-organize uploaded content (AI handles the admin)
- âœ… Persist context across sessions

**UX Requirements**:
- âœ… First-time user can upload and chat within 30 seconds
- âœ… Zero configuration required to start
- âœ… Every action provides instant visual feedback
- âœ… Error states are friendly and actionable
- âœ… Interface feels calm, not overwhelming

**Cost Optimization Requirements**:
- âœ… Response caching for repeated/similar queries
- âœ… Smart chunking to minimize token usage
- âœ… Efficient embedding strategy (batch processing)
- âœ… Demonstrate cost metrics in demo (tokens used, estimated cost)

## Implementation Phases

### Phase 1: Foundation (Days 1-3)
**Goal**: Document ingestion pipeline and basic UI shell

**Backend**:
- âœ… FastAPI project structure with async support
- âœ… Docling integration for PDF/DOCX â†’ Markdown
- âœ… gitingest/repo2txt for GitHub â†’ Markdown
- âœ… Chroma vector store setup
- âœ… Voyage 3.5 Lite embedding integration
- âœ… SQLite schema for user profiles and documents

**Frontend**:
- âœ… React + TypeScript + TailwindCSS setup
- âœ… Welcome screen with upload prompt
- âœ… Drag-and-drop file upload
- âœ… URL/GitHub input field
- âœ… Processing progress indicator

**Validation**: Can upload a PDF and see it converted to Markdown

### Phase 2: RAG Core (Days 4-6)
**Goal**: Working Q&A with document context

**Backend**:
- âœ… Document chunking pipeline (512-1024 tokens)
- âœ… DeepSeek V3.2-Exp integration
- âœ… RAG query endpoint with context retrieval
- âœ… Response caching layer
- âœ… Cost tracking (tokens, estimated cost)

**Frontend**:
- âœ… Split-pane layout (document viewer + chat)
- âœ… Markdown renderer for documents
- âœ… Focus caret (spark) implementation
- âœ… Arrow key navigation for caret
- âœ… Click-to-place caret
- âœ… Chat interface with streaming responses
- âœ… Source attribution links

**Validation**: Can ask questions about uploaded document, see focus caret work

### Phase 3: Intelligence Layer (Days 7-8)
**Goal**: Adaptive AI and user profile

**Backend**:
- âœ… User profile CRUD endpoints
- âœ… Profile inference from interactions
- âœ… Socratic system prompt with anti-sycophancy rules
- âœ… Context-aware response generation (uses caret position)

**Frontend**:
- âœ… Optional onboarding flow (background, interests)
- âœ… Suggested questions after document load
- âœ… Cost metrics display
- âœ… Session persistence

**Validation**: AI adapts to user level, remembers context across questions

### Phase 4: Polish & Demo Prep (Days 9-10)
**Goal**: Demo-ready application

**Polish**:
- âœ… Error handling and friendly error states
- âœ… Loading states and animations
- âœ… Visual refinement (Apple-level attention to detail)
- âœ… Performance optimization

**Demo Prep**:
- âœ… Prepare 3 demo documents (technical, business, creative)
- âœ… End-to-end testing with demo flow
- âœ… Documentation and README updates
- âœ… Demo script and talking points

**Validation**: Complete demo flow works flawlessly

## Risks & Mitigations

1. **Risk**: LLM API costs exceed budget
   - **Mitigation**: Implement response caching, limit document size

2. **Risk**: Document processing is too slow
   - **Mitigation**: Async processing, progress indicators

3. **Risk**: RAG responses are not relevant
   - **Mitigation**: Tune chunk size, improve prompts, test with real documents

4. **Risk**: Time runs out before core features complete
   - **Mitigation**: Strict MVP scope, daily progress checks

5. **Risk**: Integration issues between frontend/backend
   - **Mitigation**: API-first development, early integration testing

## Open Questions

**All Core Questions Resolved** âœ…

- âœ… LLM choice: DeepSeek V3.2-Exp (single model, cost-optimized via caching)
- âœ… Embedding model: Voyage 3.5 Lite (quality-first)
- âœ… Document processing: Docling + gitingest
- âœ… AI personality: Adaptive Socratic with sparse praise
- âœ… User profile: Persistent light profile (foundation for knowledge graph)
- âœ… Focus indicator: Spark/light caret with arrow key navigation
- âœ… Mobile support: Desktop-only for MVP
- âœ… Onboarding flow: 2 questions (purpose + background), skippable
- âœ… Error handling tone: Simple, concise, and informative (no technical jargon)
- âœ… Session behavior: No timeout, auto-save on every interaction, restore on refresh

**Deferred to Dedicated Sessions** (see `project-docs/future-tasks.md`):
- ğŸ¨ Visual Identity Design - dedicated deep-dive session planned
- ğŸ“„ Demo Documents Selection - choose specific documents for 3 domains
- ğŸ”„ API Resilience Strategy - handling unresponsive APIs gracefully

---

*Document Version: 1.0*
*Last Updated: January 13, 2026*
*Status: Complete - Ready for implementation*
